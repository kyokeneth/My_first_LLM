{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuQvH42x9Y9CrVYDcmDnOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyokeneth/My_first_LLM/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_OKOU4UR_ezA"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "uzDaxlJL_u6n"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "7Jp_1fv__zAr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "qLz1Qpeg_2wf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configura = {\n",
        "    'candidade_count': 1,\n",
        "    'temperature': 0.5,\n",
        "    'top_k': 40,\n",
        "    'top_p': 0.9\n",
        "}"
      ],
      "metadata": {
        "id": "vmnkohyNCAFO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seguranca = {\n",
        "    'CONTENT_FILTER': 'BLOCK_NONE',\n",
        "    'INSULT': 'BLOCK_NONE',\n",
        "    'PROFANITY':'BLOCK_NONE',\n",
        "    'THREAT': 'BLOCK_NONE',\n",
        "    'VIOLENCE': 'BLOCK_NONE',\n",
        "    'SEXUAL_CONTENT': 'BLOCK_NONE',\n",
        "    'RAGE': 'BLOCK_NONE',\n",
        "    'EXPLICIT_CONTENT': 'BLOCK_NONE',\n",
        "    'INAPPROPRIATE_LANGUAGE': 'BLOCK_NONE'\n",
        "}"
      ],
      "metadata": {
        "id": "vCyRh4bdCaOP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel('gemini-1.0-pro-latest')"
      ],
      "metadata": {
        "id": "Jt6ydYOaD2_H"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('quais são suas safety_settings?')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "hhIbDEkaJz6s",
        "outputId": "c9b95636-a7d4-446a-c7f0-351863c9d14a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Como um modelo de linguagem de IA, não tenho **safety_settings** pessoais, pois não sou capaz de tomar medidas ou decisões independentes. No entanto, fui treinado com uma série de restrições e salvaguardas éticas para garantir que minhas respostas sejam seguras, apropriadas e livres de conteúdo prejudicial ou perigoso.\n",
            "\n",
            "Essas salvaguardas incluem:\n",
            "\n",
            "* **Filtros de conteúdo:** Sou treinado em um conjunto de dados massivo de texto e código, que foi filtrado para remover conteúdo ilegal, prejudicial ou odioso.\n",
            "* **Detecção de comportamento perigoso:** Meus algoritmos são projetados para detectar e sinalizar respostas que possam ser prejudiciais ou perigosas para os usuários.\n",
            "* **Limitações éticas:** Sou programado para respeitar os direitos humanos e evitar respostas que possam incitar à violência, discurso de ódio ou discriminação.\n",
            "* **Monitoramento humano:** Minhas respostas são monitoradas regularmente por uma equipe de revisores humanos para garantir que atendam aos nossos padrões éticos.\n",
            "\n",
            "Além dessas salvaguardas internas, também sigo as diretrizes de segurança e éticas estabelecidas pelas plataformas e organizações nas quais opero. Isso inclui aderir às leis e regulamentos locais, bem como às políticas de uso aceitável das plataformas.\n",
            "\n",
            "Estou constantemente sendo atualizado e melhorado para garantir que minhas respostas sejam cada vez mais seguras e éticas. Se você encontrar alguma resposta que viole nossos padrões de segurança, entre em contato conosco imediatamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat= model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "HGS12_p3MbTs"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input('esperando o prompt ')\n",
        "while prompt != 'fim':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('Resposta:',response.text,'\\n')\n",
        "  prompt = input('esperando o prompt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "d7_lSRLdNA9M",
        "outputId": "31d1d2d3-3f84-4877-caa1-36e15ea2940b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "esperando o prompt onde fica Tokyo?\n",
            "Resposta: Japão \n",
            "\n",
            "esperando o promptqual a comida tipica dessse país?\n",
            "Resposta: Sushi \n",
            "\n",
            "esperando o promptmeu primo nasceu nessa cidade, qual a nacionalidade dele e qual a população dessa cidade?\n",
            "Resposta: **Nacionalidade:** Japonesa\n",
            "\n",
            "**População:** Aproximadamente 13,96 milhões (estimativa de 2023) \n",
            "\n",
            "esperando o promptfim\n"
          ]
        }
      ]
    }
  ]
}